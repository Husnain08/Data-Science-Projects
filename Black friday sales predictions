Jupyter Notebook


​
import pandas as pd
​
train_data = pd.read_csv('train.csv')
train_data.tail()
​
​
User_ID	Product_ID	Gender	Age	Occupation	City_Category	Stay_In_Current_City_Years	Marital_Status	Product_Category_1	Product_Category_2	Product_Category_3	Purchase
550063	1006033	P00372445	M	51-55	13	B	1	1	20	NaN	NaN	368
550064	1006035	P00375436	F	26-35	1	C	3	0	20	NaN	NaN	371
550065	1006036	P00375436	F	26-35	15	B	4+	1	20	NaN	NaN	137
550066	1006038	P00375436	F	55-80	1	C	2	0	20	NaN	NaN	365
550067	1006039	P00371644	F	46-50	0	B	4+	1	20	NaN	NaN	490

train_data.fillna(method='ffill', inplace=True)
train_data.fillna(method='bfill', inplace=True)

train_data.tail(10)
User_ID	Product_ID	Gender	Age	Occupation	City_Category	Stay_In_Current_City_Years	Marital_Status	Product_Category_1	Product_Category_2	Product_Category_3	Purchase
550058	1006024	P00372445	M	26-35	12	A	0	1	20	2.0	11.0	121
550059	1006025	P00370853	F	26-35	1	B	1	0	19	2.0	11.0	48
550060	1006026	P00371644	M	36-45	6	C	1	1	20	2.0	11.0	494
550061	1006029	P00372445	F	26-35	1	C	1	1	20	2.0	11.0	599
550062	1006032	P00372445	M	46-50	7	A	3	0	20	2.0	11.0	473
550063	1006033	P00372445	M	51-55	13	B	1	1	20	2.0	11.0	368
550064	1006035	P00375436	F	26-35	1	C	3	0	20	2.0	11.0	371
550065	1006036	P00375436	F	26-35	15	B	4+	1	20	2.0	11.0	137
550066	1006038	P00375436	F	55-80	1	C	2	0	20	2.0	11.0	365
550067	1006039	P00371644	F	46-50	0	B	4+	1	20	2.0	11.0	490

​
​
test_data = pd.read_csv('test.csv')
test_data.head()
​
​
User_ID	Product_ID	Gender	Age	Occupation	City_Category	Stay_In_Current_City_Years	Marital_Status	Product_Category_1	Product_Category_2	Product_Category_3
0	1000004	P00128942	M	46-50	7	B	2	1	1	11.0	NaN
1	1000009	P00113442	M	26-35	17	C	0	0	3	5.0	NaN
2	1000010	P00288442	F	36-45	1	B	4+	1	5	14.0	NaN
3	1000010	P00145342	F	36-45	1	B	4+	1	4	9.0	NaN
4	1000011	P00053842	F	26-35	1	C	1	0	4	5.0	12.0

test_data.fillna(method='ffill', inplace=True)
test_data.fillna(method='bfill', inplace=True)

from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
labelEncoder_for_catagories=LabelEncoder()
train_data['Gender']=labelEncoder_for_catagories.fit_transform(train_data['Gender'])
train_data['City_Category']=labelEncoder_for_catagories.fit_transform(train_data['City_Category'])
test_data['Gender']=labelEncoder_for_catagories.fit_transform(test_data['Gender'])
test_data['City_Category']=labelEncoder_for_catagories.fit_transform(test_data['City_Category'])
train_data['Age']=labelEncoder_for_catagories.fit_transform(train_data['Age'])
test_data['Age']=labelEncoder_for_catagories.fit_transform(test_data['Age'])
train_data['Stay_In_Current_City_Years']=labelEncoder_for_catagories.fit_transform(train_data['Stay_In_Current_City_Years'])
test_data['Stay_In_Current_City_Years']=labelEncoder_for_catagories.fit_transform(test_data['Stay_In_Current_City_Years'])

train_data.shape
(550068, 12)
Plotting the data

import matplotlib.pyplot as plt
import numpy as np
Preprocessing
Using One-hot encoding to convert the City_Category into a numeric value

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler
train_data=train_data
test_data=test_data
​

#train_data

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor
reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),
                          n_estimators=10000, random_state=13)

np.corrcoef(train_data['Age'], train_data['Purchase'])
array([[1.        , 0.01583859],
       [0.01583859, 1.        ]])

import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
matplotlib.style.use('ggplot')
​
plt.scatter(train_data['Age'], train_data['Purchase'])
plt.show()


X = train_data.loc[:, ['Product_Category_1','Product_Category_2','Product_Category_3']]
X.shape
(550068, 3)

y=train_data['Purchase'].values
y.shape
(550068,)

reg.fit(X,y)
AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,
           max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=None, splitter='best'),
         learning_rate=1.0, loss='linear', n_estimators=10000,
         random_state=13)

X_test=test_data.loc[:, ['Product_Category_1','Product_Category_2','Product_Category_3']]

#y_test=test_data['Purchase'].values
y_test=train_data.loc[:,['Purchase']].values
x=reg.predict(X_test)
​

x[2]
6247.780434075814

y_test[2]
array([1422], dtype=int64)

y_test.shape
(550068, 1)

​

import pandas as pd 
#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not
submission = pd.DataFrame({'User_ID':test_data['User_ID'],'Product_ID':test_data['Product_ID'],'Purchase':x})
​
#Visualize the first 5 rows
submission.head()
User_ID	Product_ID	Purchase
0	1000004	P00128942	13027.333568
1	1000009	P00113442	10240.813760
2	1000010	P00288442	6247.780434
3	1000010	P00145342	4556.387741
4	1000011	P00053842	4556.387741

​
submission.to_csv('new_dfas.csv')
​

​

​

​

​
