{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"loan_train.csv\")\n",
    "test=pd.read_csv(\"loan_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder_for_catagories=LabelEncoder()\n",
    "train['loan_status']=labelEncoder_for_catagories.fit_transform(train['loan_status'])\n",
    "train['education']=labelEncoder_for_catagories.fit_transform(train['education'])\n",
    "train['Gender']=labelEncoder_for_catagories.fit_transform(train['Gender'])\n",
    "test['loan_status']=labelEncoder_for_catagories.fit_transform(test['loan_status'])\n",
    "test['education']=labelEncoder_for_catagories.fit_transform(test['education'])\n",
    "test['Gender']=labelEncoder_for_catagories.fit_transform(test['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.loc[:,['Principal','terms','age','education','Gender']]\n",
    "y_train=train.loc[:,['loan_status']]\n",
    "x_test=test.loc[:,['Principal','terms','age','education','Gender']]\n",
    "y_test=test.loc[:,['loan_status']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying KNN Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.7222222222222222\n",
      "2 : 0.6851851851851852\n",
      "3 : 0.7407407407407407\n",
      "4 : 0.7222222222222222\n",
      "5 : 0.7407407407407407\n",
      "6 : 0.7592592592592593\n",
      "7 : 0.7407407407407407\n",
      "8 : 0.7592592592592593\n",
      "9 : 0.7407407407407407\n",
      "10 : 0.7407407407407407\n",
      "11 : 0.7407407407407407\n",
      "12 : 0.7407407407407407\n",
      "13 : 0.7407407407407407\n",
      "14 : 0.7407407407407407\n",
      "15 : 0.7407407407407407\n",
      "16 : 0.7407407407407407\n",
      "17 : 0.7407407407407407\n",
      "18 : 0.7407407407407407\n",
      "19 : 0.7407407407407407\n",
      "20 : 0.7407407407407407\n",
      "21 : 0.7407407407407407\n",
      "22 : 0.7407407407407407\n",
      "23 : 0.7407407407407407\n",
      "24 : 0.7592592592592593\n",
      "25 : 0.7592592592592593\n",
      "26 : 0.7592592592592593\n",
      "27 : 0.7592592592592593\n",
      "28 : 0.7592592592592593\n",
      "29 : 0.7407407407407407\n",
      "30 : 0.7407407407407407\n",
      "31 : 0.7407407407407407\n",
      "32 : 0.7592592592592593\n",
      "33 : 0.7407407407407407\n",
      "34 : 0.7407407407407407\n",
      "35 : 0.7407407407407407\n",
      "36 : 0.7407407407407407\n",
      "37 : 0.7407407407407407\n",
      "38 : 0.7407407407407407\n",
      "39 : 0.7407407407407407\n",
      "40 : 0.7592592592592593\n",
      "41 : 0.7407407407407407\n",
      "42 : 0.7407407407407407\n",
      "43 : 0.7407407407407407\n",
      "44 : 0.7407407407407407\n",
      "45 : 0.7407407407407407\n",
      "46 : 0.7407407407407407\n",
      "47 : 0.7407407407407407\n",
      "48 : 0.7407407407407407\n",
      "49 : 0.7407407407407407\n",
      "50 : 0.7407407407407407\n",
      "51 : 0.7407407407407407\n",
      "52 : 0.7407407407407407\n",
      "53 : 0.7407407407407407\n",
      "54 : 0.7407407407407407\n",
      "55 : 0.7407407407407407\n",
      "56 : 0.7407407407407407\n",
      "57 : 0.7407407407407407\n",
      "58 : 0.7407407407407407\n",
      "59 : 0.7407407407407407\n",
      "60 : 0.7407407407407407\n",
      "61 : 0.7407407407407407\n",
      "62 : 0.7407407407407407\n",
      "63 : 0.7407407407407407\n",
      "64 : 0.7407407407407407\n",
      "65 : 0.7407407407407407\n",
      "66 : 0.7407407407407407\n",
      "67 : 0.7407407407407407\n",
      "68 : 0.7407407407407407\n",
      "69 : 0.7407407407407407\n",
      "70 : 0.7407407407407407\n",
      "71 : 0.7407407407407407\n",
      "72 : 0.7407407407407407\n",
      "73 : 0.7407407407407407\n",
      "74 : 0.7407407407407407\n",
      "75 : 0.7407407407407407\n",
      "76 : 0.7407407407407407\n",
      "77 : 0.7407407407407407\n",
      "78 : 0.7407407407407407\n",
      "79 : 0.7407407407407407\n",
      "80 : 0.7407407407407407\n",
      "81 : 0.7407407407407407\n",
      "82 : 0.7407407407407407\n",
      "83 : 0.7407407407407407\n",
      "84 : 0.7407407407407407\n",
      "85 : 0.7407407407407407\n",
      "86 : 0.7407407407407407\n",
      "87 : 0.7407407407407407\n",
      "88 : 0.7407407407407407\n",
      "89 : 0.7407407407407407\n",
      "90 : 0.7407407407407407\n",
      "91 : 0.7407407407407407\n",
      "92 : 0.7407407407407407\n",
      "93 : 0.7407407407407407\n",
      "94 : 0.7407407407407407\n",
      "95 : 0.7407407407407407\n",
      "96 : 0.7407407407407407\n",
      "97 : 0.7407407407407407\n",
      "98 : 0.7407407407407407\n",
      "99 : 0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "score=[]\n",
    "\n",
    "for i in range(1,100):\n",
    "    knn=KNeighborsClassifier(n_neighbors=i,weights='uniform')\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    accuracy=metrics.accuracy_score(y_pred,y_test)\n",
    "    score.append(100*accuracy)\n",
    "    print(i,':',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  :  75.93 %\n"
     ]
    }
   ],
   "source": [
    "print(score.index(max(score))+1,' : ',round(max(score),2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.74      1.00      0.85        40\n",
      "\n",
      "avg / total       0.55      0.74      0.63        54\n",
      "\n",
      "\n",
      "\n",
      "Jaccard Similarity Score :  74.07 %\n",
      "\n",
      "\n",
      "F1-SCORE :  [0.         0.85106383]\n",
      "\n",
      "\n",
      "Train Accuracy:  75.14450867052022 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,jaccard_similarity_score,log_loss,f1_score\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n')\n",
    "print('Jaccard Similarity Score : ',round(jaccard_similarity_score(y_test,y_pred)*100,2),'%')\n",
    "print('\\n')\n",
    "print('F1-SCORE : ',f1_score(y_test,y_pred,average=None))\n",
    "print('\\n')\n",
    "print('Train Accuracy: ',metrics.accuracy_score(y_train, knn.predict(x_train))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The optimal value of K is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2 Using Decision Tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "F:\\nff\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier(max_depth=5,criterion='entropy',max_features=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(x_train,y_train)\n",
    "y_pred_tree=dtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.74      1.00      0.85        40\n",
      "\n",
      "avg / total       0.55      0.74      0.63        54\n",
      "\n",
      "\n",
      "\n",
      "Jaccard Similarity Score :  74.07 %\n",
      "\n",
      "\n",
      "F1-SCORE :  [0.         0.85106383]\n",
      "\n",
      "\n",
      "Train Accuracy:  76.01156069364163 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n')\n",
    "print('Jaccard Similarity Score : ',round(jaccard_similarity_score(y_test,y_pred)*100,2),'%')\n",
    "print('\\n')\n",
    "print('F1-SCORE : ',f1_score(y_test,y_pred,average=None))\n",
    "print('\\n')\n",
    "print('Train Accuracy: ',metrics.accuracy_score(y_train, dtree.predict(x_train))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part-3 Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svm=SVC().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm=svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.74      0.97      0.84        40\n",
      "\n",
      "avg / total       0.55      0.72      0.62        54\n",
      "\n",
      "\n",
      "\n",
      "Jaccard Similarity Score :  72.22 %\n",
      "\n",
      "\n",
      "F1-SCORE :  [0.         0.83870968]\n",
      "\n",
      "\n",
      "Train Accuracy:  76.01156069364163 %\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_svm))\n",
    "print('\\n')\n",
    "print('Jaccard Similarity Score : ',round(jaccard_similarity_score(y_test,pred_svm)*100,2),'%')\n",
    "print('\\n')\n",
    "print('F1-SCORE : ',f1_score(y_test,pred_svm,average=None))\n",
    "print('\\n')\n",
    "print('Train Accuracy: ',metrics.accuracy_score(y_train, svm.predict(x_train))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4 Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgm=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgm=lgm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        14\n",
      "          1       0.74      1.00      0.85        40\n",
      "\n",
      "avg / total       0.55      0.74      0.63        54\n",
      "\n",
      "\n",
      "\n",
      "Jaccard Similarity Score :  74.07 %\n",
      "\n",
      "\n",
      "F1-SCORE :  [0.         0.85106383]\n",
      "\n",
      "\n",
      "Train Accuracy:  75.14450867052022 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "F:\\nff\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_lgm))\n",
    "print('\\n')\n",
    "print('Jaccard Similarity Score : ',round(jaccard_similarity_score(y_test,pred_lgm)*100,2),'%')\n",
    "print('\\n')\n",
    "print('F1-SCORE : ',f1_score(y_test,pred_lgm,average=None))\n",
    "print('\\n')\n",
    "print('Train Accuracy: ',metrics.accuracy_score(y_train, lgm.predict(x_train))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
